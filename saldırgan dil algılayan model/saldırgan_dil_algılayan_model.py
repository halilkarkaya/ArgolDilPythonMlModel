# -*- coding: utf-8 -*-
"""saldırgan dil algılayan model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/halilkarakaya3/sald-rgan-dil-alg-layan-model.ae7d361d-3cf9-47c0-b7da-19a7de6a5f84.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250331/auto/storage/goog4_request%26X-Goog-Date%3D20250331T140051Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D9e6b4e83b2ccb88613b8128b24a5cf4030dcffc7e50ae448e105c2f77c3801dac375fed9765d717b7ac4be450115e180e109a3806363bfce93020536a9b45148e8469e596fffb79defc787cc7d92c3aa1e8a47458d01faba0d12560c614ed80f8cfee9e54494b5686c46f9b60b4f30a1fe931167e98e7bfe27f490fe0ffc299d0b396fb0c17b754a6643850ef8b7f1deb87430d9643ab820fc89765ba4649847be2c4492394f41087366760707c19d55556ef1019795584d7388020d7fe23eb3993bd6f36a73564d5bda6ce7e6e09715a2abe5c78f842f597d64aa6525418f0eb4530386fac38709bf3533607ca6e50b2d3ba2f0477d078949ef5f7782e07b23
"""

import numpy as np
import pandas as pd
import string
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# dataset link= https://huggingface.co/datasets/Toygar/turkish-offensive-language-detection/viewer



splits = {'train': 'train.csv', 'validation': 'valid.csv', 'test': 'test.csv'}
df = pd.read_csv("hf://datasets/Toygar/turkish-offensive-language-detection/" + splits["train"])

df.tail(3)

mesaj=input("saldıragan olduğunuzu düşündüğünüz içeriği giriniz")

dff=pd.DataFrame({"text":mesaj,"label":0},index=[1])

dfY=pd.concat([df,dff],ignore_index=True)

#tüm harfleri küçük harf yaptık
df["text"]=df["text"].str.lower()

#df['text']'te bulunan noktalama işaretlerini kaldırıyoruz.

for i in string.punctuation:
    df['text']=df['text'].str.replace(i," ")
    df['text']=df['text'].str.replace("  ","")

# bizim tahminimiz için önemli olmayacak kelimeleri kaldırıyoruz

stopwords=['fakat','lakin','ancak','acaba', 'ama', 'aslında', 'az', 'bazı', 'belki',
           'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da', 'daha',
           'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her',
           'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim', 'mı', 'mu', 'mü', 'nasıl',
           'ne', 'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki',
           'şey', 'siz', 'şu', 'tüm', 've', 'veya', 'ya', 'yani',
           #getfeatureden sonra benim eklediklerim
          """ "di","un","user","li","ki","her","hangi",'ol', 'olabilir', 'olacak', 'olan', 'olarak',
           'oldu', 'oldum', 'olduğu', 'olduğunu', 'olmak', 'olması',
           'olmayan', 'olmaz', 'olmuş', 'olsa', 'olsun', 'olun', 'olunca',
           'olup', 'olur', 'olursa', 'oluyor', 'ona', 'onlar', 'onu', 'onun','https', 'icin','mi'
           '10', '15', '20', '30','bile', 'bin', 'bir', 'biraz', 'birlikte', 'bizde', 'bize', 'bizi',
           'bizim', 'bişey','bu', 'bugün', 'buna', 'bundan',
           'bunlar', 'bunları', 'bunların', 'bunu', 'bunun', 'burada',
           'burda', 'böyle', 'bütün', 'büyük """ ]

for s in stopwords:
    s=" "+s+" "
    df['text']=df['text'].str.replace(s," ")

#en sık kullanılan 400 kelimeyle işlem yapar

cv=CountVectorizer(max_features=1000)
# df["text"]'teki verileri alır sayısal değerlere dönüştürür
x=cv.fit_transform(dfY["text"]).toarray()
#sayısal değerleri görüntülemek için
x

#modelimiz için önemli olabilecek kelimeler burda modeliniz işine yaramayacağını düşündüğünüz kelimeleri stopwordslerin içineekleyebilirsiniz
cv.get_feature_names_out()

y=dfY["label"]

#bizim tahminimiz son satırda onu alıyoruz
tahmin=x[-1]

x=x[0:-1]
y=y.iloc[0:-1]

#son elemana kadar tüm x ve y verilerini x ve y eşitledik

print(x.shape)
print(y.shape)

x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=19,train_size=0.70)
#aşırı öğrenmeyi önlemek için veri setini %70 train(öğrenme) %30 test verisi olarak bölüyoruz

#bağımlı değişkenimiz kategorik olduğu için problemimizi sınıflandırma algoritması olan randomforestclassifier'le çözmek istedim
rf=RandomForestClassifier(n_estimators=5)
#öğrenme aşaması
model=rf.fit(x_train,y_train)
#test aşaması
skor=rf.score(x_test,y_test)
#bizim tahminimiz
sonuc=model.predict([tahmin])
skor=round(skor,2)*100

#çıktı ekranımız
if(sonuc==1):
    print(f"saldırgan bir dil kullanmış yüzde {skor} ihtimalle")
if(sonuc==0):
    print(f"saldırgan bir dil yok {skor} ihtimalle")

sonuc



